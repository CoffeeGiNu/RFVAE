digraph {
	graph [size="16.95,16.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139710516053632 [label="
 (1, 1, 28, 28)" fillcolor=darkolivegreen1]
	139710515705504 [label=PermuteBackward0]
	139710515705984 -> 139710515705504
	139710515705984 [label=ReshapeAliasBackward0]
	139710515705888 -> 139710515705984
	139710515705888 [label=SigmoidBackward0]
	139710515705648 -> 139710515705888
	139710515705648 [label=AddmmBackward0]
	139710515698448 -> 139710515705648
	139710515838336 [label="decoder.affine_3.bias
 (1)" fillcolor=lightblue]
	139710515838336 -> 139710515698448
	139710515698448 [label=AccumulateGrad]
	139710515698688 -> 139710515705648
	139710515698688 [label=SoftplusBackward0]
	139710515699792 -> 139710515698688
	139710515699792 [label=AddmmBackward0]
	139710515694704 -> 139710515699792
	139710515838176 [label="decoder.affine_2.bias
 (512)" fillcolor=lightblue]
	139710515838176 -> 139710515694704
	139710515694704 [label=AccumulateGrad]
	139710515695952 -> 139710515699792
	139710515695952 [label=SoftplusBackward0]
	139710515698016 -> 139710515695952
	139710515698016 [label=AddmmBackward0]
	139710515703584 -> 139710515698016
	139710515838016 [label="decoder.affine_1.bias
 (256)" fillcolor=lightblue]
	139710515838016 -> 139710515703584
	139710515703584 [label=AccumulateGrad]
	139710515703872 -> 139710515698016
	139710515703872 [label=ReshapeAliasBackward0]
	139710515699168 -> 139710515703872
	139710515699168 [label=PermuteBackward0]
	139710515702384 -> 139710515699168
	139710515702384 [label=CatBackward0]
	139710515699408 -> 139710515702384
	139710515699408 [label=ExpandBackward0]
	139710515706800 -> 139710515699408
	139710515706800 [label=AddBackward0]
	139710515706896 -> 139710515706800
	139710515706896 [label=MeanBackward1]
	139710516068512 -> 139710515706896
	139710516068512 [label=ConvolutionBackward0]
	139710516068608 -> 139710516068512
	139710516068608 [label=SoftplusBackward0]
	139710516068800 -> 139710516068608
	139710516068800 [label=ConvolutionBackward0]
	139710516068896 -> 139710516068800
	139710516068896 [label=SoftplusBackward0]
	139710516069088 -> 139710516068896
	139710516069088 [label=ConvolutionBackward0]
	139710516069184 -> 139710516069088
	139710515837216 [label="encoder.conv_1.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	139710515837216 -> 139710516069184
	139710516069184 [label=AccumulateGrad]
	139710516069136 -> 139710516069088
	139710515836496 [label="encoder.conv_1.bias
 (32)" fillcolor=lightblue]
	139710515836496 -> 139710516069136
	139710516069136 [label=AccumulateGrad]
	139710516068848 -> 139710516068800
	139710515837376 [label="encoder.conv_2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139710515837376 -> 139710516068848
	139710516068848 [label=AccumulateGrad]
	139710516068704 -> 139710516068800
	139710515837456 [label="encoder.conv_2.bias
 (64)" fillcolor=lightblue]
	139710515837456 -> 139710516068704
	139710516068704 [label=AccumulateGrad]
	139710516068560 -> 139710516068512
	139710515837136 [label="encoder.mean_layer.weight
 (10, 64, 4, 4)" fillcolor=lightblue]
	139710515837136 -> 139710516068560
	139710516068560 [label=AccumulateGrad]
	139710516068416 -> 139710516068512
	139710515837696 [label="encoder.mean_layer.bias
 (10)" fillcolor=lightblue]
	139710515837696 -> 139710516068416
	139710516068416 [label=AccumulateGrad]
	139710515706848 -> 139710515706800
	139710515706848 [label=MulBackward0]
	139710516068752 -> 139710515706848
	139710516068752 [label=ExpBackward0]
	139710516069040 -> 139710516068752
	139710516069040 [label=MeanBackward1]
	139710516069232 -> 139710516069040
	139710516069232 [label=ConvolutionBackward0]
	139710516068608 -> 139710516069232
	139710516069328 -> 139710516069232
	139710515837776 [label="encoder.logvar_layer.weight
 (10, 64, 4, 4)" fillcolor=lightblue]
	139710515837776 -> 139710516069328
	139710516069328 [label=AccumulateGrad]
	139710516069280 -> 139710516069232
	139710515837856 [label="encoder.logvar_layer.bias
 (10)" fillcolor=lightblue]
	139710515837856 -> 139710516069280
	139710516069280 [label=AccumulateGrad]
	139710515699120 -> 139710515698016
	139710515699120 [label=TBackward0]
	139710515699360 -> 139710515699120
	139710515837936 [label="decoder.affine_1.weight
 (256, 12)" fillcolor=lightblue]
	139710515837936 -> 139710515699360
	139710515699360 [label=AccumulateGrad]
	139710515696480 -> 139710515699792
	139710515696480 [label=TBackward0]
	139710515698976 -> 139710515696480
	139710515838096 [label="decoder.affine_2.weight
 (512, 256)" fillcolor=lightblue]
	139710515838096 -> 139710515698976
	139710515698976 [label=AccumulateGrad]
	139710515699312 -> 139710515705648
	139710515699312 [label=TBackward0]
	139710515699216 -> 139710515699312
	139710515838256 [label="decoder.affine_3.weight
 (1, 512)" fillcolor=lightblue]
	139710515838256 -> 139710515699216
	139710515699216 [label=AccumulateGrad]
	139710515705504 -> 139710516053632
	139710516053792 [label="
 (784, 1)" fillcolor=darkolivegreen3]
	139710515705888 -> 139710516053792
	139710516053792 -> 139710516053632 [style=dotted]
}
